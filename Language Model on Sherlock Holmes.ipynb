{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## TODO:\n",
    "\n",
    " * better batching mechanism (maybe the prebuilt in TF)\n",
    " * try different optimizer (SGD with momentum, RMSProp) ?\n",
    " * learning rate decay ?\n",
    " * dropout, more layers, gradient clipping, bidirectional, ... ?\n",
    " * beam search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "import numpy as np\n",
    "import re\n",
    "import nltk\n",
    "import tensorflow as tf\n",
    "import itertools"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prepare vocabulary and a training set\n",
    "\n",
    "I load the Sherlock holmes corpus and process it as follows:\n",
    " * All is converted to lowercase, all whitespace collapsed to a single space\n",
    " * nltk is used to tokenize into sentences and words. Special tokens START and END are added to the beginning and end of each sentence\n",
    " * Only the first 500 sentences are used for training (for simplicity and speed of learning)\n",
    " * All words are kept. Later we may drop all words frequent less than a threshold, or replace them with UNKNOWN token\n",
    " * Longer sentences are trimmed to length of 50 words, shorter sentences are padded (and masking is used in the training)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "with open('../txa-hw/hw2/pg1661.txt', encoding='utf-8') as f:\n",
    "    original_text = f.read()\n",
    "# Strip meta info and table of contents at the beginning and licence at the end -> use only the book itself.\n",
    "text = original_text[re.search('ADVENTURE I', original_text).start() : re.search('End of the Project Gutenberg EBook', original_text).start()]\n",
    "text = text.lower().strip()\n",
    "text = re.sub('\\s+', ' ', text) # replace whitespaces with single space"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "sentences = nltk.sent_tokenize(text)\n",
    "\n",
    "token_start = 'START'\n",
    "token_end = 'END'\n",
    "tok_sentences = [[token_start] + [w for w in nltk.word_tokenize(s) if w] + [token_end] for s in sentences]\n",
    "\n",
    "train_size = 100  # limit training set to this number of first sentences\n",
    "tok_sentences = tok_sentences[:train_size]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "freq_dist = nltk.FreqDist(itertools.chain(*tok_sentences))\n",
    "\n",
    "freq_threshold = 0\n",
    "vocab = [(k,v) for k,v in freq_dist.items() if v >= freq_threshold]\n",
    "vocab_size = len(vocab)\n",
    "id_word = [v[0] for v in vocab]\n",
    "word_id = {w:i for i,w in enumerate(id_word)}\n",
    "\n",
    "# drop all words not in vocabulary (less frequent than freq_threshold)\n",
    "# maybe to replace them with special token would be better?\n",
    "# now we actually don't drop anything\n",
    "tok_sentences = [[w for w in s if w in word_id] for s in tok_sentences]\n",
    "\n",
    "max_len = 50\n",
    "\n",
    "# cut all sentences to max_len\n",
    "tok_sentences = [s[:max_len] for s in tok_sentences]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "662"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vocab_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X = [[word_id[w] for w in s[:-1]] for s in tok_sentences]\n",
    "Y = [[word_id[w] for w in s[1:]] for s in tok_sentences]  # shift-by-1 X, next-word prediction\n",
    "\n",
    "X_lens = np.asarray([len(x) for x in X])\n",
    "# Y_lens = [len(y) for y in Y]\n",
    "\n",
    "# pad with zeros to max_len\n",
    "X = np.asarray([np.pad(x, (0,max_len-len(x)), 'constant') for x in X])\n",
    "Y = np.asarray([np.pad(y, (0,max_len-len(y)), 'constant') for y in Y])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Build model and train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from lstm_language_model import RNNLanguageModel\n",
    "\n",
    "# reload the module and reimport in case of change in code\n",
    "import importlib\n",
    "import lstm_language_model\n",
    "importlib.reload(lstm_language_model)\n",
    "from lstm_language_model import RNNLanguageModel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "num_steps = max_len  # max. number of timesteps\n",
    "embeding_size = 100\n",
    "input_size = X.shape[0]\n",
    "batch_size = 32\n",
    "lstm_size = 100 # n_hidden and state_size?\n",
    "learning_rate = 0.01\n",
    "checkpoint_path = 'checkpoints/sherlock.ckp'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "tf.reset_default_graph()\n",
    "sess = tf.Session()\n",
    "# sess = tf.Session(config=tf.ConfigProto(log_device_placement=True))\n",
    "\n",
    "model = RNNLanguageModel(embedding_size=embeding_size, learning_rate=learning_rate, lstm_size=lstm_size, num_steps=num_steps, vocab_size=vocab_size, sess=sess, checkpoint_path=checkpoint_path)\n",
    "model.build(model_type='train')\n",
    "\n",
    "sess.run(tf.global_variables_initializer())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 1\n",
      "epoch 2\n",
      "training loss after 5 steps: 4.62144517899 elapsed time: 00h 00m 01s\n",
      "epoch 3\n",
      "epoch 4\n",
      "training loss after 10 steps: 3.47606348991 elapsed time: 00h 00m 02s\n",
      "saved model to checkpoints/sherlock.ckp-10\n",
      "epoch 5\n",
      "training loss after 15 steps: 2.41555380821 elapsed time: 00h 00m 04s\n",
      "epoch 6\n",
      "epoch 7\n",
      "training loss after 20 steps: 1.50818240643 elapsed time: 00h 00m 05s\n",
      "saved model to checkpoints/sherlock.ckp-20\n",
      "epoch 8\n",
      "epoch 9\n",
      "training loss after 25 steps: 0.845472693443 elapsed time: 00h 00m 08s\n",
      "epoch 10\n",
      "training loss after 30 steps: 0.496541559696 elapsed time: 00h 00m 09s\n",
      "saved model to checkpoints/sherlock.ckp-30\n",
      "epoch 11\n",
      "epoch 12\n",
      "training loss after 35 steps: 0.364254385233 elapsed time: 00h 00m 11s\n",
      "epoch 13\n",
      "epoch 14\n",
      "training loss after 40 steps: 0.309825122356 elapsed time: 00h 00m 12s\n",
      "saved model to checkpoints/sherlock.ckp-40\n",
      "epoch 15\n",
      "training loss after 45 steps: 0.282669723034 elapsed time: 00h 00m 15s\n",
      "epoch 16\n",
      "epoch 17\n",
      "training loss after 50 steps: 0.273558914661 elapsed time: 00h 00m 16s\n",
      "saved model to checkpoints/sherlock.ckp-50\n",
      "epoch 18\n",
      "epoch 19\n",
      "training loss after 55 steps: 0.267974495888 elapsed time: 00h 00m 18s\n",
      "epoch 20\n",
      "training loss after 60 steps: 0.262608885765 elapsed time: 00h 00m 19s\n",
      "saved model to checkpoints/sherlock.ckp-60\n",
      "Finished training\n",
      "Saved final model to checkpoints/sherlock.ckp-final\n",
      "Final training loss: 0.262608885765\n",
      "It took 00h 00m 23s\n"
     ]
    }
   ],
   "source": [
    "n_epochs = 20\n",
    "\n",
    "model.train(X, Y, X_lens, n_epochs, batch_size, evaluate_every=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x118d54a8>]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXoAAAD8CAYAAAB5Pm/hAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x149a2be0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.semilogy(model.losses)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "sess.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generate text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Restoring parameters from checkpoints/sherlock.ckp-final\n"
     ]
    }
   ],
   "source": [
    "tf.reset_default_graph()\n",
    "sess = tf.Session()\n",
    "model.sess = sess\n",
    "model.build(model_type='infer')\n",
    "model.saver.restore(sess, checkpoint_path + '-final')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "this account of you we have from all quarters received . END \n",
      "`` 'eg i had seen little of holmes lately . END \n",
      "and yet i believe that my eyes are as good as yours . '' END \n",
      "`` seven ! '' END \n",
      "i carefully examined the writing , and the paper upon which it written . END \n",
      "`` the name of the maker , no doubt ; or his monogram , rather . '' END \n",
      "with hardly a word spoken , but with a kindly eye , he waved me to an armchair , threw across his case of cigars , and indicated a spirit case and a gasogene in the corner . END \n",
      "but the note itself . END \n",
      "`` i see it , i deduce it , and . END \n",
      "the distinction is clear . END \n",
      "i did so , and saw a large `` e '' with a small `` g , '' a `` p , '' and a large `` g '' with a small `` t '' woven into the texture of the paper . END \n",
      "for example , you have frequently seen the steps which lead up from the hall to this room . '' END \n",
      "adventure i. a scandal in bohemia i. to sherlock holmes she is always the woman . END \n",
      "`` what do you imagine that it means ? '' END \n",
      "it seldom was ; but woman was glad , i think , to see me . END \n",
      "he was still would , have 's . END \n",
      "with hardly a word spoken , but with a kindly eye , he waved me to an armchair , threw across his case of cigars , and indicated a spirit case and a gasogene in the corner . END \n",
      "hold it up to the light . '' END \n",
      "your recent services to one of the royal houses of europe have shown that you are one who may safely be trusted with matters which are of an importance which can hardly be exaggerated . END \n",
      "i rang the bell and was shown up to the chamber which had formerly been in part my own . END \n",
      "`` how many ? END \n",
      "`` is not an english paper at all . END \n",
      "under hold motives me to be so ridiculously simple that i could easily do it myself , though at each successive instance of your reasoning i am baffled until you explain your process process moment . END \n",
      "`` such paper could not be bought under half a crown a packet . END \n",
      "`` frequently . '' END \n",
      "`` it is not an english paper at all . END \n",
      "`` such paper could not be bought under half a crown a packet . END \n",
      "`` the man who wrote it was presumably well to do , '' i remarked , endeavouring to imitate my companion 's processes . END \n",
      "he never spoke of the softer passions , save with a gibe and a "
     ]
    }
   ],
   "source": [
    "seq = ['START']\n",
    "seq = [word_id[s] for s in seq]\n",
    "state = init_state = np.zeros((2, 1, lstm_size))\n",
    "\n",
    "num_words = 500\n",
    "\n",
    "for i in range(len(seq)-1, num_words):\n",
    "    p, state = model.infer(np.reshape(seq[-1], (1,1)), np.array([1]), state)\n",
    "#     max_id = np.argmax(p)\n",
    "    p = p.reshape([-1])\n",
    "    max_id = np.random.choice(list(range(len(p))), p=p)\n",
    "    seq.append(max_id)\n",
    "    print(id_word[max_id], end=' ')\n",
    "    if max_id == word_id[token_end]: # restart the sentence\n",
    "        print()\n",
    "        seq.append(word_id[token_start])\n",
    "        state = init_state"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:pisa-txa]",
   "language": "python",
   "name": "conda-env-pisa-txa-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
