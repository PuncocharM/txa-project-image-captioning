{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note: this needs python 2.7 kernel"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Results\n",
    "\n",
    "\n",
    "<table>\n",
    "<tr><th>Model</th><th>B-1</th><th>B-2</th><th>B-3</th><th>B-4</th><th>Meteor</th><th>CIDEr</th><th>ROUGE_L</th></tr>\n",
    "<tr><td>1-nn euclidean fc6</td><td>0.467</td><td>0.274</td><td>0.162</td><td>0.099</td><td>-</td><td>0.347</td><td>0.351</td></tr>\n",
    "<tr><td>1-nn cosine fc6</td><td>0.492</td><td>0.296</td><td>0.179</td><td>0.111</td><td>-</td><td>0.400</td><td>0.366</td></tr>\n",
    "<tr><td>1-nn cosine xception</td><td>0.509</td><td>0.312</td><td>0.191</td><td>0.119</td><td>-</td><td>0.464</td><td>0.379</td></tr>\n",
    "</table>\n",
    "\n",
    "B-n means BLEU-n, 1-nn = nearest neighbour with cosine or eucleidean distance with AlexNet fc6, fc7 or Xception descriptors.\n",
    "\n",
    "I don't measure Meteor because of some errors that I may try to fix later (it internally calls to .jar to evaluate)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "from pycocotools.coco import COCO\n",
    "from coco_caption.pycocoevalcap.eval import COCOEvalCap\n",
    "import matplotlib.pyplot as plt\n",
    "import skimage.io as io\n",
    "import pylab\n",
    "pylab.rcParams['figure.figsize'] = (10.0, 8.0)\n",
    "\n",
    "import json\n",
    "from json import encoder\n",
    "encoder.FLOAT_REPR = lambda o: format(o, '.3f')\n",
    "\n",
    "from config import ms_coco_dir"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loading annotations into memory...\n",
      "Done (t=0.17s)\n",
      "creating index...\n",
      "index created!\n",
      "Loading and preparing results...\n",
      "DONE (t=0.03s)\n",
      "creating index...\n",
      "index created!\n",
      "tokenization...\n",
      "setting up scorers...\n",
      "computing Bleu score...\n",
      "{'reflen': 50131, 'guess': [51951, 46951, 41951, 36951], 'testlen': 51951, 'correct': [26439, 8966, 3010, 1065]}\n",
      "ratio: 1.03630488121\n",
      "Bleu_1: 0.509\n",
      "Bleu_2: 0.312\n",
      "Bleu_3: 0.191\n",
      "Bleu_4: 0.119\n",
      "computing Rouge score...\n",
      "ROUGE_L: 0.379\n",
      "computing CIDEr score...\n",
      "CIDEr: 0.464\n"
     ]
    }
   ],
   "source": [
    "resFile = 'predictions/knn-xception-cosine.json'\n",
    "\n",
    "annFile = '%s/annotations/captions_val2017.json' % ms_coco_dir\n",
    "\n",
    "coco = COCO(annFile)\n",
    "cocoRes = coco.loadRes(resFile)\n",
    "\n",
    "cocoEval = COCOEvalCap(coco, cocoRes)\n",
    "cocoEval.params['image_id'] = cocoRes.getImgIds()  # evaluate on a subset of images\n",
    "cocoEval.evaluate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "with open(resFile[:-5] + '-evaluation.json', 'w') as f:\n",
    "    json.dump(cocoEval.eval, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:pisa-txa-2-7]",
   "language": "python",
   "name": "conda-env-pisa-txa-2-7-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
